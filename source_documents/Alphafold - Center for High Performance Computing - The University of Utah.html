<!DOCTYPE HTML><html lang="en-US" class="no-js">
   <head><!-- PAGE HEAD -->
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
      <title>Alphafold - Center for High Performance Computing - The University of Utah</title>
      <meta name="keywords" content="">
      <meta name="description" content="">
      <meta name="robots" content="index,follow">
      <link rel="icon" href="//templates.utah.edu/_main-v3-1/images/template/favicon.ico">
      <link rel="apple-touch-icon-precomposed" href="//templates.utah.edu/_main-v3-1/images/template/apple-touch-icon.png">
      <link rel="stylesheet" href="//templates.utah.edu/_main-v3-1/css/main.min.css" type="text/css"><noscript>
         <link rel="stylesheet" href="//templates.utah.edu/_main-v3-1/css/assets/fontawesome/css/all.min.css" type="text/css"></noscript><link href="/_resources/css/custom.css" rel="stylesheet" type="text/css">
      <script src="//templates.utah.edu/_main-v3-1/js/head-code.min.js"></script>
      <!-- HEAD CODE -->
      
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y160DVJ0DZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Y160DVJ0DZ');
</script>

      
      <!-- END HEAD CODE -->
      <!-- END PAGE HEAD -->
      </head>
   <body class="has-headernav"><!-- PAGE BODY -->
      <a class="uu-skip-link" href="#skip-link-target">Skip to content</a>
      <!-- BODY TOP CODE -->
            <!-- END BODY TOP CODE -->
      
      <div id="uu-top-target" class="uu-site"><!-- SEARCH -->
         <div class="uu-search" role="search">
    <div class="uu-search__container">
        <!-- SITE SEARCH -->
        <form method="get" id="search-site" class="uu-search__form" action="/search/index.php">

            <label for="inputSearchSite" class="sr-only">Search Site:</label>
            <input type="text" id="inputSearchSite" name="q" value="" placeholder="Search Site" />
            <input type="hidden" name="gcse_action" value="site" />

            <div class="form-powered-by">
                <span>Powered by</span> 
                <img src="https://templates.utah.edu/_main-v3-1/images/template/google-logo.png" alt="Google Search">
            </div>

        </form>
        <!-- END SITE SEARCH -->
        <!-- CAMPUS SEARCH -->
        <form method="get" id="search-campus" class="uu-search__form" action="/search/index.php">

            <label for="inputSearchCampus" class="sr-only">Search Campus:</label>
            <input type="text" id="inputSearchCampus" name="q" value="" placeholder="Search Campus" />
            <input type="hidden" name="gcse_action" value="campus" />

            <div class="form-powered-by">
                <span>Powered by</span> 
                <img src="https://templates.utah.edu/_main-v3-1/images/template/google-logo.png" alt="Google Search">
            </div>
        </form>
        <!-- END CAMPUS SEARCH -->

        <!-- SEARCH TYPE TOGGLE -->
        <div class="search-type-toggle">
            <label class="uu-switch" for="search_campus_checkbox">
                <input type="checkbox" name="search_campus_checkbox" value="" id="search_campus_checkbox">
                <span class="uu-switch-slider"></span>
                <span class="uu-switch-label">Search Campus</span>
            </label>
        </div>
        <!-- END SEARCH TYPE TOGGLE -->

    </div>
</div><!-- END SEARCH -->
         <!-- HEADER -->
         
         <header class="uu-header">
            <div class="uu-header__container">
               <!-- ALERT AREA -->
               <div id="alert_bar" class="uu-alert-bar"> 
	<a href="https://coronavirus.utah.edu/">University of Utah COVID-19 Updates</a>
</div><!-- END ALERT AREA -->
               
               <div class="uu-header__top"> <a href="https://www.utah.edu/" class="uu-header__logo"><span class="sr-only">The University of Utah</span></a>                  <div class="uu-header__middle">
                     <!-- HEADER TITLE -->
                     <div class="uu-header__title">
<h2><a href="/">CHPC - Research Computing and Data Support for the University</a></h2>
<!-- <h3><a href="http://it.utah.edu">University Information Technology</a></h3> --></div><!-- END HEADER TITLE -->
                     <!-- HEADER NAVIGATION -->
                     
<nav class="uu-header__nav">
	
<ul class="uu-menu__level1">
<ul class="uu-menu__level1">
<li class="has-sub"><a href="#">About Us</a>
<ul class="sub-menu">
<li><a href="/about/index.php">About Us</a></li>
<li><a href="https://www.chpc.utah.edu/about/vision.php">Vision</a></li>
<li><a href="/about/staff.php">Staff</a></li>
<li><a href="https://www.chpc.utah.edu/about/contact.php">Contact Information</a></li>
<li><a href="https://www.chpc.utah.edu/about/acknowledge.php">Acknowledging CHPC</a></li>
<li><a href="https://www.chpc.utah.edu/highlights.php">Research Highlights</a></li>
<li><a href="https://www.chpc.utah.edu/about/partners.php">Partners</a></li>
<li><a href="/news/index.php">News</a></li>
<li><a href="/about/governance.php">Governance</a></li>
</ul>
</li>
<li class="has-sub"><a href="#">Resources</a>
<ul class="sub-menu">
<li><a href="https://www.chpc.utah.edu/resources/index.php">Resources</a></li>
<li><a href="https://www.chpc.utah.edu/resources/HPC_Clusters.php">HPC Clusters</a></li>
<li><a href="/resources/storage_services.php">Storage Services</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/data_services.php">Data Transfer Services</a></li>
<li><a href="/resources/virtualmachines.php">Virtual Machines</a></li>
<li><a href="/resources/hosting.php">Hosting Services</a></li>
<li><a href="/resources/Networking.php">Networking</a></li>
<li><a href="/resources/ProtectedEnvironment.php">Protected Environment</a></li>
<li><a href="/documentation/software/ai.php">ML/AI Resources</a></li>
<li><a href="/userservices/index.php">User Services</a></li>
</ul>
</li>
<li class="has-sub sub-width-lg"><a href="#">Documentation</a>
<ul class="sub-menu">
<li><a href="https://www.chpc.utah.edu/documentation/index.php">Documentation</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/gettingstarted.php">Getting Started</a></li>
<li><a href="https://www.chpc.utah.edu/resources/access.php">Accessing Our Resources</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/videos/index.php">Short Training Videos</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/index.php">Cluster Guides</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/beehive.php">Beehive User Guide (Windows Server)</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/gpus-accelerators.php">GPU &amp; Accelerators</a></li>
<li><a href="/documentation/software/ai.php">ML/AI Resources</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/frisco-nodes.php">Frisco Nodes</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/narwhal.php">Narwhal User Guide (Protected Environment Statistics)</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/software/index.php">Software</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/ProgrammingGuide.php">Programming Guide</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/policies/index.php">Policy Manual</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/data_services.php">Data Transfer Services</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/HelloWorldMPI.php">HPC Basics - Hello World MPI</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/faq.php">Frequently Asked Questions</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/white_papers/index.php">White Papers</a></li>
</ul>
</li>
<li class="has-sub"><a href="#">User Services</a>
<ul class="sub-menu">
<li><a href="/userservices/index.php">User Services</a></li>
<li><a href="https://www.chpc.utah.edu/userservices/accounts.php">Accounts</a></li>
<li><a href="/userservices/allocations.php">Allocations</a></li>
<li><a href="/userservices/gettinghelp.php">Getting Help</a></li>
<li><a href="https://www.chpc.utah.edu/presentations/index.php">Training</a></li>
</ul>
</li>
<li class="has-sub sub-width-lg"><a href="#">Usage</a>
<ul class="sub-menu">
<li><a href="/usage/cluster/index.php">Cluster Usage</a>
<ul>
<li><a href="/usage/cluster/current-project-general.php">General Allocation Pool</a></li>
<li><a href="/usage/cluster/current-project-lonepeak.php">Lonepeak Cluster</a></li>
<li><a href="/usage/cluster/current-project-kingspeak.php">Kingspeak Cluster</a></li>
<li><a href="/usage/cluster/current-project-ash.php">Ash Cluster</a></li>
<li><a href="/usage/cluster/current-project-redwood.php">Redwood Cluster</a></li>
</ul>
</li>
<li><a href="/usage/graphs.php?g=cluster%20utilization&amp;host=combined&amp;type=daily_utilization">Cluster Utilization Graphs</a></li>
<li><a href="/usage/graphs.php?g=hpc%20cluster%20scratch&amp;host=chpc_gen&amp;type=cpu">HPC Cluster Scratch</a></li>
<li><a href="/usage/graphs.php?g=network&amp;host=Campus+Gateway&amp;type=daily_traffic">Network</a>
<ul>
<li><a href="/resources/maddash-dashboards.php">Maddash Dashboards</a></li>
</ul>
</li>
<li><a href="http://weathermap.uen.net/" target="_blank" rel="noopener">UEN Weathermap (Only Available on UEN Networks)</a></li>
<li><a href="http://snapp2.bldc.grnoc.iu.edu/i2al2s/#&amp;p=3%2C42&amp;ccid=3&amp;tab=1&amp;search=undefined&amp;pwidth=undefined&amp;ccat=undefined&amp;url=show-graph.cgi%3Fcollection_ids%3D145%26end%3D1461772131%26start%3D1461771831%26cf%3DAVERAGE%26ds%3Doutput%2Cinput%26collection_ids%3D145" target="_blank" rel="noopener">UEN Aggregate Utilization</a></li>
<li><a href="http://uofu.status.io">UofU IT Services Status</a></li>
<li><a href="https://status.it.utah.edu">University Application Heath Summary - NOC</a></li>
</ul>
</li>
<li><a href="/role/">My Account</a></li>
</ul>
</ul>	
</nav>

<!-- END HEADER NAVIGATION -->
                     </div>
                  <div class="uu-search-toggle"><button class="uu-search__trigger"><span class="far fa-search" aria-hidden="true"></span><span class="sr-only">Search</span></button></div><button id="jsNavTrigger" class="uu-nav__trigger" aria-haspopup="true" aria-expanded="false"><span class="sr-only">Reveal Menu</span><span></span></button></div>
            </div>
         </header>
         <!-- END HEADER -->
         <!-- PUSH NAVIGATION -->
         
         <section class="uu-nav">
            <div class="uu-nav__container"><button id="jsMobileNavTrigger" class="uu-nav__trigger" aria-haspopup="true" aria-expanded="false"><span class="sr-only">Reveal Menu</span><span></span></button><header class="uu-nav__header">
                  <h2 class="sr-only">Main Navigation</h2>
                  <!-- Navigation Logo -->
<a href="https://utah.edu/" class="uu-nav__logo">
	<img src="https://templates.utah.edu/_main-v3-1/images/template/university-of-utah-logo.svg" alt="The University of Utah"/>
</a></header>
               <nav class="uu-menu" aria-label="main"><p><h2 class="uu-menu__title">Main Menu</h2>
<hr />
<ul class="uu-menu__level1">
<li><a href="/">Home</a></li>
<li class="has-sublist"><a href="#">About Us</a>
<ul class="uu-menu__level2">
<li><a href="/about/index.php">About Us</a></li>
<li><a href="https://www.chpc.utah.edu/about/vision.php">Vision</a></li>
<li><a href="/about/staff.php">Staff</a></li>
<li><a href="https://www.chpc.utah.edu/about/contact.php">Contact Information</a></li>
<li><a href="https://www.chpc.utah.edu/about/acknowledge.php">Acknowledging CHPC</a></li>
<!--<li><a href="/about/bibliography/CHPC%20BIB.pdf" target="_blank" rel="noopener">CHPC Bibliography</a></li>-->
<li><a href="https://www.chpc.utah.edu/about/SupportedResearch.php">Supported Research</a></li>
<li><a href="https://www.chpc.utah.edu/highlights.php">Research Highlights</a></li>
<li><a href="https://www.chpc.utah.edu/about/partners.php">Partners</a></li>
<li><a href="/news/index.php">News</a></li>
<li><a title="University Information Technology" href="https://it.utah.edu/" target="_blank" rel="noopener">UIT</a></li>
<li><a href="/about/governance.php">Governance</a></li>
</ul>
</li>
<li class="has-sublist"><a href="#">Resources</a>
<ul class="uu-menu__level2">
<li><a href="https://www.chpc.utah.edu/resources/index.php">Resources</a></li>
<li><a href="https://www.chpc.utah.edu/resources/HPC_Clusters.php">HPC Clusters</a></li>
<li><a href="/resources/storage_services.php">Storage Services</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/data_services.php">Data Transfer Services</a></li>
<li><a href="/resources/virtualmachines.php">Virtual Machines</a></li>
<li><a href="/resources/hosting.php">Hosting Services</a></li>
<li><a href="/resources/Networking.php">Networking</a></li>
<li><a href="/resources/ProtectedEnvironment.php">Protected Environment</a></li>
<li><a href="/documentation/software/ai.php">AI/ML Resources</a></li>
<li><a href="/userservices/index.php">User Services</a></li>
</ul>
</li>
<li class="has-sublist"><a href="#">Documentation</a>
<ul class="uu-menu__level2">
<li><a href="https://www.chpc.utah.edu/documentation/index.php">Documentation</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/gettingstarted.php">Getting Started</a></li>
<li><a href="https://www.chpc.utah.edu/resources/access.php">Accessing Our Resources</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/videos/index.php">Short Training Videos</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/index.php">Cluster Guides</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/beehive.php">Beehive User Guide (Windows Server)</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/gpus-accelerators.php">GPU &amp; Accelerators</a></li>
<li><a href="/documentation/software/ai.php">ML/AI Resources</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/frisco-nodes.php">Frisco Nodes</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/narwhal.php">Narwhal User Guide (Protected Environment Statistics)</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/software/index.php">Software</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/ProgrammingGuide.php">Programming Guide</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/policies/index.php">Policy Manual</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/data_services.php">Data Transfer Services</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/guides/HelloWorldMPI.php">HPC Basics - Hello World MPI</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/faq.php">Frequently Asked Questions</a></li>
<li><a href="https://www.chpc.utah.edu/documentation/white_papers/index.php">White Papers</a></li>
</ul>
</li>
<li class="has-sublist"><a href="#">User Services</a>
<ul class="uu-menu__level2">
<li><a href="/userservices/index.php">User Services</a></li>
<li><a href="https://www.chpc.utah.edu/userservices/accounts.php">Accounts</a></li>
<li><a href="/userservices/allocations.php">Allocations</a></li>
<li><a href="/userservices/gettinghelp.php">Getting Help</a></li>
<li><a href="https://www.chpc.utah.edu/presentations/index.php">Training</a></li>
</ul>
</li>
<li class="has-sublist"><a href="#">Usage</a>
<ul class="uu-menu__level2">
<li class="has-sublist"><a href="/usage/cluster/index.php">Cluster Usage</a>
<ul class="uu-menu__level3">
<li><a href="/usage/cluster/current-project-general.php">General Allocation Pool</a></li>
<li><a href="/usage/cluster/current-project-lonepeak.php">Lonepeak Cluster</a></li>
<li><a href="/usage/cluster/current-project-kingspeak.php">Kingspeak Cluster</a></li>
<li><a href="/usage/cluster/current-project-ash.php">Ash Cluster</a></li>
<li><a href="/usage/cluster/current-project-redwood.php">Redwood Cluster</a></li>
</ul>
</li>
<li><a href="/usage/graphs.php?g=cluster%20utilization&amp;host=combined&amp;type=daily_utilization">Cluster Utilization Graphs</a></li>
<li><a href="/usage/graphs.php?g=hpc%20cluster%20scratch&amp;host=chpc_gen&amp;type=cpu">HPC Cluster Scratch</a></li>
<li class="has-sublist"><a href="/usage/graphs.php?g=network&amp;host=Campus+Gateway&amp;type=daily_traffic">Network</a>
<ul class="uu-menu__level3">
<li><a href="/resources/maddash-dashboards.php">Maddash Dashboards</a></li>
</ul>
</li>
<li class="has-sublist"><a href="http://weathermap.uen.net/" target="_blank" rel="noopener">UEN Weathermap</a>
<ul class="uu-menu__level3">
<li><a href="http://weathermap.uen.net/" target="_blank" rel="noopener">(Only Available on UEN Networks)</a></li>
</ul>
</li>
<li><a href="http://snapp2.bldc.grnoc.iu.edu/i2al2s/#&amp;p=3%2C42&amp;ccid=3&amp;tab=1&amp;search=undefined&amp;pwidth=undefined&amp;ccat=undefined&amp;url=show-graph.cgi%3Fcollection_ids%3D145%26end%3D1461772131%26start%3D1461771831%26cf%3DAVERAGE%26ds%3Doutput%2Cinput%26collection_ids%3D145" target="_blank" rel="noopener">UEN Aggregate Utilization</a></li>
<li><a href="http://uofu.status.io">UofU IT Services Status</a></li>
<li><a href="https://status.it.utah.edu">University Application Heath Summary - NOC</a></li>
</ul>
</li>
<li><a href="/role/">My Account</a></li>
</ul></p></nav>
            </div>
         </section>
         <!-- END PUSH NAVIGATION -->
         
         <!-- MAIN CONTENT -->
         <main class="uu-main" id="skip-link-target">
            <nav aria-label="Breadcrumb" class="uu-breadcrumb">
               <ol>
                  <li><a href="/">Home</a></li>
                  <li><a href="/documentation/">documentation</a></li>
                  <li><a href="/documentation/software/">software</a></li>
                  <li><span class="sr-only">current page: </span>Alphafold</li>
               </ol>
            </nav>
            <!-- SECTION 1 -->
            
            <section class="uu-section bg-white text-default uu-section--region-1" style="">
               <div class="uu-section__container"><!-- SECTION HEADER -->
                  
                  <div class="uu-section__header  ">
                     <h1>Alphafold and Colabfold</h1>
                     <ul id="in_text_nav" class="crawl_skip">
                        <li class="crawl_skip" style="margin-left: 0px;"><a href="#alphafold">Alphafold</a></li>
                        <li class="crawl_skip" style="margin-left: 0px;"><a href="#colabfold">Colabfold</a></li>
                     </ul>
                  </div>
                  <!-- END SECTION HEADER -->
                  <!-- REGION 1 -->
                  
                  <div class="uu-section__region bg-white text-default no-border"><!--crawl_skip-->
                     <p><a title="Alphafold" href="https://github.com/deepmind/alphafold" target="_blank" rel="noopener">Alphafold </a>is a novel program for protein structure prediction, using neural network run on GPUs
                        to provide protein structures, which accuracy is comparable to laborious manual structure
                        simulations. <a title="Colabfold" href="https://github.com/sokrypton/ColabFold" target="_blank" rel="noopener">Colabfold </a>uses Alphafold, but replaces the time consuming database searches with much faster,
                        but less accurate alternatives.</p>
                     <h2><a id="alphafold"></a>Alphafold</h2>
                     <p><span>Alphafold consists of two major steps, the first being the genetic database searches
                           for the amino-acid sequence, defined by the input fasta file, which run completely
                           on the CPUs, are very I/O intensive, don't parallelize much, and don't utilize GPUs.
                           The second part is utilizing the pre-trained neural network coupled with molecular
                           dynamics simulations refinement to provide the 3D protein structure in a form of a
                           PDB file. This step uses GPUs for the neural network inference, and optionally for
                           the molecular dynamics simulation. Therefore the scarce GPU resource is only utilized
                           by a part of the workflow.</span></p>
                     <p><span>To make things worse, this first database search step runs very slowly, when the genetic
                           databases are located on a network mounted storage, which is the most commonly used
                           storage on the CHPC clusters. We investigated performance of the database search on
                           all CHPC network file systems, and neither provides acceptable results&nbsp; - a small
                           protein sequence search took 8-16 hours to complete depending on a file system used.
                           The best alternative is to create a RAM disk on the node where the Alphafold simulation
                           runs, and copy the small databases and indices of the large databases onto this RAM
                           disk for fast access. This brings down the database search part in the aforementioned
                           example to 40 minutes.&nbsp;</span></p>
                     <p><span>We have created a script to create the RAM disk and copy the databases to it, located
                           at<code> /uufs/chpc.utah.edu/sys/installdir/alphafold/db_to_tmp_232.sh</code>. Note that the databases on the RAM disk occupy ~25 GB so ask for RAM for the job
                           accordingly. The file copy is fairly fast, it takes about a minute. Also make sure
                           that the databases are removed at the end of the job. Below we provide shell commands
                           and SLURM script that does this.</span></p>
                     <p><span>Also, since some databases are on the RAM disk and some on the network mounted storage,
                           Alphafold must be run with options that reflect the database locations. Since we package
                           the Alphafold distribution in a Singularity container, the Alphafold launch command
                           gets even more complicated, however, this is all shown in the examples below. To make
                           this simpler, we have created several wrapper scripts to make the launch command simpler.</span></p>
                     <p><span>The second, neural network / MD part, in our example, takes 12 minutes on a 1080ti
                           GPU, while it would take 3.5 hours on a CPU using 16 cores of the notchpeak-shared-short
                           partition.</span></p>
                     <p><span>As we can see from the above mentioned example timings, out of the 52 minutes the
                           job ran, the GPU was utilized only for 12 minutes. For this reason, we have modified
                           the Alphafold source to run the CPU and GPU intense parts as separate jobs. The first
                           job does the database search only on CPUs utilizing the protein sequence databases
                           on the RAM disk. The second job runs the GPU intensive neural network part, which
                           does not need many CPUs and the RAM disk.&nbsp;</span></p>
                     <p><span>Colabfold (see below) is a reasonable alternative which uses alternative database
                           search engine, which is less detailed but much faster.</span></p>
                     <h4><span>Running Alphafold interactively</span></h4>
                     <p><span>When learning to use Alphafold, or setting up a new type of simulation, we recommend
                           to use the notchpeak-shared-short interactive queue, as that leads to quicker turnaround
                           if errors are encountered. Once you have done that, create SLURM scripts as shown
                           in the next section, that allows to run both the CPU and GPU parts via a single job
                           submission.</span></p>
                     <p><span><strong>First</strong> we submit an interactive job on the notchpeak cluster asking for <strong>16 CPUs</strong> and <strong>128 GB of memory</strong> to run the database search. The database search is more memory intensive, plus, we
                           need extra memory for the RAM disk databases in order to get better performance.&nbsp;</span></p>
                     <pre><span>salloc -N 1 -n 16 --mem=128G -p notchpeak-shared-short -A notchpeak-shared-short -t 8:00:00</span></pre>
                     <p>Then we load the Alphafold module and set up the RAM disk databases, located in /tmp,
                        which is a RAM disk:</p>
                     <pre>ml alphafold/2.3.2<br>/uufs/chpc.utah.edu/sys/installdir/alphafold/db_to_tmp_232.sh</pre>
                     <p>Now we are ready to run Alphafold. This can be done either with the<span><code>run_alphafold.sh</code> command</span> which requires explicit listing of the database location parameters, or with the
                        <span><code>run_alphafold_full.sh</code></span>command which defines the locations of the databases, so only additional runtime parameters
                        need to be listed. This includes the user supplied parameters such as the FASTA input
                        file name, which we define through a bash shell environment variable FASTA_FILE, and
                        the output directory, defined by OUTPUT_DIR variable</p>
                     <pre>export FASTA_FILE=ex1.fasta<br>export OUTPUT_DIR=my_out_dir<br>export SCRDB=/scratch/general/vast/app-repo/alphafold<br>export TMPDB=/tmp/$SLURM_JOBID<br># run_alphafold.sh is an alias defined in the modulefile, requiring to list the appropriate databases<br>#run_alphafold.sh --data_dir=$SCRDB --uniref90_database_path=$SCRDB/uniref90/uniref90.fasta --uniref30_database_path=$TMPDB/UniRef30_2021_03 --mgnify_database_path=$SCRDB/mgnify/mgy_clusters_2022_05.fa --bfd_database_path=$TMPDB/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt --pdb70_database_path=$TMPDB/pdb70 --template_mmcif_dir=$SCRDB/pdb_mmcif/mmcif_files --obsolete_pdbs_path=$SCRDB/pdb_mmcif/obsolete.dat --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01 --run_feature=1<br># run_alphafold_full.sh is an alias that includes the list of the full databases in the argument list, so one only needs to provide the run specific runtime options<br>run_alphafold_full.sh --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01 --run_feature=1</pre>
                     <p><span>Notice the option use <code>--run_feature=1</code> which tells the program to run only the database search, and saves a file called
                           <code>features.pkl</code> which contains the database search results for each fasta file. Once this file is
                           written, the first step is finished, and we can delete this job.</span></p>
                     <p><span>For reduced databases, which are useful for larger sequences or multimers, use the
                           <code>run_alphafold_full.sh</code> command, which points to these reduced databases.</span></p>
                     <p><span><strong>Second </strong>we submit an interactive job on the notchpeak cluster asking for <strong>4 CPUs</strong> to run and <strong>one GPU</strong> to run the GPU intensive part. The GPU part does not need many CPUs, and uses less
                           memory, though with larger sequences one may need to ask for more than 16 GB that
                           are the default for 4 CPUs on notchpeak-shared-short.</span></p>
                     <pre><span>salloc -N 1 -n 4 -p notchpeak-shared-short -A notchpeak-shared-short -t 8:00:00 --gres=gpu:1080ti</span></pre>
                     <p>Run the second part of Alphafold as</p>
                     <pre>export FASTA_FILE=ex1.fasta<br>export OUTPUT_DIR=my_out_dir<br>export SCRDB=/scratch/general/vast/app-repo/alphafold<br>export TMPDB=/scratch/general/vast/app-repo/alphafold<br>#run_alphafold.sh --data_dir=$SCRDB --uniref90_database_path=$SCRDB/uniref90/uniref90.fasta --uniref30_database_path=$TMPDB/UniRef30_2021_03 --mgnify_database_path=$SCRDB/mgnify/mgy_clusters_2022_05.fa --bfd_database_path=$TMPDB/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt --pdb70_database_path=$TMPDB/pdb70 --template_mmcif_dir=$SCRDB/pdb_mmcif/mmcif_files --obsolete_pdbs_path=$SCRDB/pdb_mmcif/obsolete.dat --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01<br># run_alphafold_full.sh is an alias that includes the list of the full databases in the argument list, so one only needs to provide the run specific runtime options<br>run_alphafold_full.sh --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01</pre>
                     <p>Notice that we use <code>--use-gpu_relax</code> to run the molecular dynamics (MD) relaxation on a GPU, we have noticed that on small
                        structures the CPU relaxation is faster, while for larger structures the GPU is faster.
                        Since we ask for smaller CPU count to run the GPU intensive part, we choose to run
                        the MD on the GPU.To see all the runtime options, run <code>run_alphafold.sh --help</code>.</p>
                     <p>This launch command is for a monomer, for multimer, some of the database parameters
                        are different. Notice that we are also using the reduced databases:</p>
                     <pre>/uufs/chpc.utah.edu/sys/installdir/alphafold/db_to_tmp_232_reduced.sh<br>run_alphafold_red.sh --fasta_paths=$FASTA_FILE --max_template_date=2022-06-27 --output_dir=$OUTPUT_DIR --use_gpu_relax --model_preset=multimer --db_preset=reduced_dbs --run_feature=1</pre>
                     <p>Note that the command above only does the CPU intensive part on the CPU, the GPU intensive
                        part will need to be run as well with</p>
                     <pre>run_alphafold_red.sh --fasta_paths=$FASTA_FILE --max_template_date=2022-06-27 --output_dir=$OUTPUT_DIR --use_gpu_relax --model_preset=multimer --db_preset=reduced_dbs</pre>
                     <h4>Running Alphafold in a job script</h4>
                     <p>We are providing a sample SLURM scripts that in essence does the steps outlined above
                        at <code>/uufs/chpc.utah.edu/sys/installdir/alphafold/run_alphafold_chpc_232.slr</code> for the first step, and <code>/uufs/chpc.utah.edu/sys/installdir/alphafold/run_alphafold_chpc_232_2.slr</code> for the second step. Note the "232" at the end of the script which denotes the Alphafold
                        version. Because of the explicit launch of Alphafold from the container necessitated
                        by the RAM disk databases, we need to explicitly call the appropriate container version.</p>
                     <p>The databases need about 25 GB worth of RAM on the RAM disk, so make sure to add this
                        RAM to the amount requested with the #SBATCH --mem option.</p>
                     <p>The first step SLURM script, <code>run_alphafold_chpc_232.slr,</code> then looks like:</p>
                     <pre>#!/bin/bash<br>#SBATCH -t 8:00:00<br>#SBATCH -n 16<br>#SBATCH -N 1<br>#SBATCH -p notchpeak-shared-short<br>#SBATCH -A notchpeak-shared-short<br>#SBATCH --mem=128G<br><br># this script runs the first, CPU intensive, part of AlphaFold<br>ml purge<br>ml alphafold/2.3.2<br><br># put the name of the fasta file here<br>export FASTA_FILE="t1050.fasta"<br>export OUTPUT_DIR="out"<br># copy some of the databases to the RAM disk<br>/uufs/chpc.utah.edu/sys/installdir/alphafold/db_to_tmp_232.sh<br><br>SCRDB=/scratch/general/vast/app-repo/alphafold<br>TMPDB=/tmp/$SLURM_JOBID<br><br>sbatch -d afterok:$SLURM_JOBID run_alphafold_chpc_232_2.slr<br><br># run_alphafold.sh is an alias defined in the modulefile, requiring to list the appropriate databases<br>#run_alphafold.sh --data_dir=$SCRDB --uniref90_database_path=$SCRDB/uniref90/uniref90.fasta --uniref30_database_path=$TMPDB/UniRef30_2021_03 --mgnify_database_path=$SCRDB/mgnify/mgy_clusters_2022_05.fa --bfd_database_path=$TMPDB/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt --pdb70_database_path=$TMPDB/pdb70 --template_mmcif_dir=$SCRDB/pdb_mmcif/mmcif_files --obsolete_pdbs_path=$SCRDB/pdb_mmcif/obsolete.dat --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01 --run_feature=1<br># run_alphafold_full.sh is an alias that includes the list of the full databases in the argument list, so one only needs to provide the run specific runtime options<br>run_alphafold_full.sh --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01 --run_feature=1<br><br>rm -rf $TMPDB</pre>
                     <p>Again, we are only asking for CPUs (as many as possible, the database search to certain
                        extent utilizes more CPUs). We are also submitting the second step from this job with
                        the <code>-d afterok:$SLURM_JOBID</code>, which submits the second step job with dependence after this first CPU step finishes
                        correctly.</p>
                     <p>The second GPU intensive step, <code>run_alphafold_chpc_232_2.slr,</code> runs on a few CPUs, needs less memory and does not use the RAM disk for the databases,
                        since they are not used - just need to be fed to the run_alphafold.sh command since
                        it checks if these databases exist. Notice also that we are not passing the FASTA_FILE
                        and OUTPUT_DIR environment variables, they are by default passed from the first job.</p>
                     <pre>#!/bin/bash<br>#SBATCH -t 8:00:00<br>#SBATCH -n 4<br>#SBATCH -N 1<br>#SBATCH -p notchpeak-shared-short<br>#SBATCH -A notchpeak-shared-short<br>#SBATCH --gres=gpu:t4:1<br>#SBATCH --mem=32G<br><br># this script runs the second, GPU intensive, part of AlphaFold<br>ml purge<br>ml alphafold/2.3.2<br><br># FASTA_FILE and OUTPUT_DIR are brought from the previous job<br><br># no use of databases so no need to create them in /tmp<br>SCRDB=/scratch/general/vast/app-repo/alphafold<br>TMPDB=/scratch/general/vast/app-repo/alphafold<br><br># run_alphafold.sh is an alias defined in the modulefile, requiring to list the appropriate database<br>#run_alphafold.sh --data_dir=$SCRDB --uniref90_database_path=$SCRDB/uniref90/uniref90.fasta --uniref30_database_path=$TMPDB/UniRef30_2021_03 --mgnify_database_path=$SCRDB/mgnify/mgy_clusters_2022_05.fa --bfd_database_path=$TMPDB/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt --pdb70_database_path=$TMPDB/pdb70 --template_mmcif_dir=$SCRDB/pdb_mmcif/mmcif_files --obsolete_pdbs_path=$SCRDB/pdb_mmcif/obsolete.dat --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01<br># run_alphafold_full.sh is an alias that includes the list of the full databases in the argument list, so one only needs to provide the run specific runtime options<br>run_alphafold_full.sh --use_gpu_relax --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --max_template_date=2022-01-01 -data_dir=$SCRDB --uniref90_database_path=$SCRDB/uniref90/uniref90.fasta --uniref30_database_path=$TMPDB/uniref30/UniRef30_2021_03 --mgnify_database_path=$SCRDB/mgnify/mgy_clusters_2022_05.fa --bfd_database_path=$TMPDB/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt --pdb70_database_path=$TMPDB/pdb70/pdb70 --template_mmcif_dir=$SCRDB/pdb_mmcif/mmcif_files --obsolete_pdbs_path=$SCRDB/pdb_mmcif/obsolete.dat --fasta_paths=$FASTA_FILE --output_dir=$OUTPUT_DIR --use_gpu_relax --max_template_date=2022-01-01</pre>
                     <p>When running your own jobs, you may need to change the SLURM account (-A), partition
                        (-p), memory (--mem) or GPU type (--gres=gpu), depending on the size of the job and
                        the accounts, partitions and GPUs you have access to.</p>
                     <p>Once the two job scripts are ready submit the first one with the <code>sbatch</code>&nbsp; command. The second job gets submitted automatically from the first job:</p>
                     <p><code>sbatch run_alphafold_chpc_232.slr</code></p>
                     <p>For the multimer with reduced databases, example script is at <code>/uufs/chpc.utah.edu/sys/installdir/alphafold/run_alphafold_chpc_multimer_232.slr</code>&nbsp; and <code>/uufs/chpc.utah.edu/sys/installdir/alphafold/run_alphafold_chpc_multimer_232_2.slr</code>. Note mainly the different databases that are being used in the command line, and
                        calling a different script, <code>/uufs/chpc.utah.edu/sys/installdir/alphafold/db_to_tmp_232_reduced.sh</code> , to copy the databases to the RAM disk.</p>
                     <h2><a id="colabfold"></a>Colabfold</h2>
                     <p>Colabfold is an adaptation of Alphafold run using the Google Colab cloud, which includes
                        modified database search resulting in faster performance. Since running Jupyter notebooks
                        on a Google Colab cloud infrastructure may be impractical for our users, we have set
                        up an adaptation of Colabfold, called <a title="localcollabfold" href="https://github.com/YoshitakaMo/localcolabfold">localcolabfold</a>, which allows Colabfold to run locally, e.g. on an HPC cluster.</p>
                     <p>The database search is done on a shared remote server, which means that with increased
                        usage this remote server may become a bottleneck. For that reason please be judicious
                        with submitting Colabfold jobs. Once we reach a point of high use, we may need to
                        look into setting up a dedicated local server for the database searches.&nbsp;</p>
                     <p>To run Colabfold, we load the module and run the command:</p>
                     <pre>ml colabfold<br>export FASTA_FILE=ex1.fasta<br>export OUTPUT_DIR=my_output_dir<br>colabfold_batch --amber --templates --num-recycle 3 --use-gpu-relax $FASTA_FILE $OUTPUT_DIR</pre>
                     <p>These commands can be either typed after one starts an interactive GPU job, as shown
                        at the Alphafold interactive example above, or put into a SLURM script, replacing
                        the Alphafold module and commands in the SLURM script shown above. The SLURM script
                        would then look like this:</p>
                     <pre>#!/bin/bash<br>#SBATCH -t 8:00:00<br>#SBATCH -n 16<br>#SBATCH -N 1<br>#SBATCH -p notchpeak-shared-short<br>#SBATCH -A notchpeak-shared-short<br>#SBATCH --gres=gpu:1080ti:1<br><br>ml colabfold<br>export FASTA_FILE=ex1.fasta<br>export OUTPUT_DIR=my_output_dir<br>colabfold_batch --amber --templates --num-recycle 3 --use-gpu-relax $FASTA_FILE $OUTPUT_DIR</pre>
                  </div>
                  <!-- END REGION 1 -->
                  <!-- SECTION FOOTER -->
                  
                  <div class="uu-section__footer  ">
                     <p></p>
                  </div>
                  <!-- END SECTION FOOTER -->
                  </div>
            </section>
            <!-- END SECTION 1 -->
            <!-- SECTION 2 -->
            <!-- END SECTION 2 -->
            <!-- SECTION 3 -->
            <!-- END SECTION 3 -->
            <!-- SECTION 4 -->
            <!-- END SECTION 4 -->
            <!-- SECTION 5 -->
            <!-- END SECTION 5 -->
            </main>
         <!-- END MAIN CONTENT -->
         <!-- FOOTER -->
         
         <footer class="uu-footer"><div class="uu-footer__top">
   <div class="uu-footer__top-container">
      <div class="uu-footer__top-col1"><a href="https://www.utah.edu"><img src="https://templates.utah.edu/_main-v3-1/images/template/blocku.svg" alt="The University of Utah" class="uu-block-logo"></a><div class="department-name">
            <h2>The Center For High Performance Computing</h2>
         </div>
         <div class="department-address">
            <p>155 S 1452 E, RM. 405<br>SLC, UT 84112-0190<br>801.585.3791&nbsp;</p>
         </div>
      </div>
      <div class="uu-footer__top-col2">
         <h2 class="footer-heading">Stay in Touch</h2>
         <hr>
         <ul>
            <li><a href="https://map.utah.edu/index.html?code=inscc">Find Us</a></li>
            <li><a href="https://www.chpc.utah.edu/about/contact.php">Contact Us</a></li>
            <li><a href="mailto:helpdesk@chpc.utah.edu">Webmaster</a></li>
         </ul>
      </div>
      <div class="uu-footer__top-col5">
         <h2 class="footer-heading">Quick Links</h2>
         <hr>
         <ul>
            <li><a href="https://www.utah.edu/a-z/">A-Z Index</a></li>
            <li><a href="https://people.utah.edu/uWho/basic.hml">Campus Directory</a></li>
            <li><a href="https://www.map.utah.edu">Campus Map</a></li>
            <li><a href="https://map.utah.edu/?allshuttle=on">Shuttle Tracker </a></li>
            <li><a href="https://cis.utah.edu/">CIS</a></li>
            <li><a href="https://www.umail.utah.edu/">UMail</a></li>
            <li><a href="https://attheu.utah.edu/">@ The U</a></li>
         </ul>
      </div>
   </div>
</div><div class="uu-footer__bottom">
   <div class="uu-footer__bottom-container">
      <div class="uu-footer__bottom-col1"><a href="https://www.utah.edu/"><img src="https://templates.utah.edu/_main-v3-1/images/template/university-of-utah-logo.svg" alt="The University of Utah" class="uu-site-logo"></a></div>
      <div class="uu-footer__bottom-col2">
         <div class="legal">
            <p>© 2024 The University of Utah</p>
            <ul>
               <li><a href="https://www.utah.edu/indigenous-land-acknowledgment/index.php">Indigenous Land Acknowledgment</a></li>
               <li><a href="https://www.utah.edu/nondiscrimination/">Nondiscrimination &amp; Accessibility</a></li>
               <li><a href="https://www.utah.edu/disclaimer/">Disclaimer</a></li>
               <li><a href="https://www.utah.edu/privacy/">Privacy</a></li>
               <li><a href="https://www.utah.edu/credits-v3.php">Credits &amp; Attributions</a></li>
               <li><a href="https://attheu.utah.edu/media-contacts/">Media Contacts</a></li>
               <li><span id="directedit"></span></li>
            </ul>
         </div>
      </div>
      <div class="uu-footer__bottom-col3">
         <ul class="uu-social-list">
            <li><a href="https://twitter.com/uutah"><span class="fa-brands fa-x-twitter" aria-hidden="true"></span><span class="sr-only">X</span></a></li>
            <li><a href="https://www.facebook.com/universityofutah"><span class="fab fa-facebook" aria-hidden="true"></span><span class="sr-only">Facebook</span></a></li>
            <li><a href="https://www.instagram.com/universityofutah/"><span class="fab fa-instagram" aria-hidden="true"></span><span class="sr-only">Instagram</span></a></li>
            <li><a href="https://www.youtube.com/user/theuniversityofutah"><span class="fab fa-youtube" aria-hidden="true"></span><span class="sr-only">Youtube</span></a></li>
         </ul>
      </div>
   </div>
</div></footer>
         <!-- END FOOTER -->
         </div>
      <!-- FOOT CODE -->
      <script src="//templates.utah.edu/_main-v3-1/js/main.min.js"></script>
      
      
      
      
      
      
      <script src="//templates.utah.edu/_main-v3-1/js/directedit.js"></script><script><!--
window.onload = function(){ directedit(); }
//
			--></script>
      <script src="/_resources/js/custom.js"></script>
            
      <!-- END FOOT CODE -->
      
      <div id="hidden"><a id="de" href="https://a.cms.omniupdate.com/11/?skin=utah&amp;account=utah_home&amp;site=chpc2&amp;action=de&amp;path=/documentation/software/alphafold.pcf">Last Updated: 12/19/23</a></div>
      <!-- END PAGE BODY -->
      </body>
</html>